{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6ZkRNUIMb9HR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output dir: C:\\Users\\aayus\\Downloads\\DES646 Course Project\\analysis_outputs\n"
          ]
        }
      ],
      "source": [
        "import os, ast, re, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "OUTDIR = Path(\"analysis_outputs\")\n",
        "OUTDIR.mkdir(exist_ok=True)\n",
        "print(\"Output dir:\", OUTDIR.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Load & Basic Clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading: materials_final_with_price.csv\n",
            "Shape: (2456, 34)\n",
            "Example categories: [['Ceramic', 'Glass'], ['Ceramic', 'Oxide'], ['Metal', 'Nonferrous Metal', 'Pure Element'], ['Ceramic', 'Oxide', 'Aluminum Oxide'], ['Ceramic', 'Oxide']]\n"
          ]
        }
      ],
      "source": [
        "dataset_path = \"materials_final_with_price.csv\"\n",
        "\n",
        "print(\"Loading:\", dataset_path)\n",
        "df = pd.read_csv(dataset_path, dtype=str)\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "if \"Material Name\" not in df.columns:\n",
        "    for cand in [\"material\", \"Material\"]:\n",
        "        if cand in df.columns:\n",
        "            df = df.rename(columns={cand: \"Material Name\"})\n",
        "            break\n",
        "if \"Material Name\" not in df.columns:\n",
        "    raise ValueError(\"No 'Material Name' column detected.\")\n",
        "\n",
        "def parse_categories(x):\n",
        "    if isinstance(x, list): return x\n",
        "    s = \"\" if pd.isna(x) else str(x)\n",
        "    if s.strip().startswith(\"[\") and s.strip().endswith(\"]\"):\n",
        "        try:\n",
        "            lst = ast.literal_eval(s)\n",
        "            return [str(t).strip() for t in lst]\n",
        "        except Exception:\n",
        "            pass\n",
        "    return [p.strip() for p in s.split(\";\") if p.strip()]\n",
        "\n",
        "df[\"__categories_list\"] = df[\"Categories\"].apply(parse_categories) if \"Categories\" in df.columns else [[]]*len(df)\n",
        "print(\"Example categories:\", df[\"__categories_list\"].head().tolist())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Coerce mixed strings to numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coerced numerics on candidate columns: 30\n"
          ]
        }
      ],
      "source": [
        "text_like = {\"Material Name\",\"Categories\",\"Material Notes\",\"Thermal Properties\",\"Optical Properties\",\"__categories_list\"}\n",
        "candidate_num_cols = [c for c in df.columns if c not in text_like]\n",
        "\n",
        "num_extract = re.compile(r\"[-+]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?\")\n",
        "\n",
        "def coerce_numeric(val):\n",
        "    if val is None or (isinstance(val, float) and math.isnan(val)):\n",
        "        return np.nan\n",
        "    s = str(val)\n",
        "    m = num_extract.search(s)\n",
        "    if not m: \n",
        "        return np.nan\n",
        "    try:\n",
        "        return float(m.group(0))\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "for c in candidate_num_cols:\n",
        "    df[c] = df[c].apply(coerce_numeric)\n",
        "\n",
        "print(\"Coerced numerics on candidate columns:\", len(candidate_num_cols))\n",
        "df.to_csv(OUTDIR/\"_stage1_coerced.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Category mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_cols = [c for c in df.columns if c not in {\"Material Name\",\"Categories\",\"Material Notes\",\"__categories_list\"} and pd.api.types.is_numeric_dtype(df[c])]\n",
        "from collections import defaultdict\n",
        "\n",
        "cat_means = {col: defaultdict(list) for col in num_cols}\n",
        "for _, r in df.iterrows():\n",
        "    cats = r[\"__categories_list\"] if isinstance(r[\"__categories_list\"], list) else []\n",
        "    for col in num_cols:\n",
        "        v = r[col]\n",
        "        if not pd.isna(v):\n",
        "            for cat in cats:\n",
        "                cat_means[col][cat].append(v)\n",
        "\n",
        "for col in num_cols:\n",
        "    for cat, vals in cat_means[col].items():\n",
        "        cat_means[col][cat] = float(np.nanmean(vals)) if len(vals) else np.nan\n",
        "\n",
        "global_means = {col: float(np.nanmean(df[col])) for col in num_cols}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Category-weighted Imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imputation complete.\n"
          ]
        }
      ],
      "source": [
        "def impute_row(row):\n",
        "    cats = row[\"__categories_list\"] if isinstance(row[\"__categories_list\"], list) else []\n",
        "    weights = [0.6, 0.3, 0.1]\n",
        "    out = {}\n",
        "    for col in num_cols:\n",
        "        v = row[col]\n",
        "        if not pd.isna(v):\n",
        "            out[col] = v\n",
        "            continue\n",
        "        acc, wsum = 0.0, 0.0\n",
        "        for i, cat in enumerate(cats[:3]):\n",
        "            w = weights[i]\n",
        "            m = cat_means[col].get(cat, np.nan)\n",
        "            if not (m is None or np.isnan(m)):\n",
        "                acc += w*m\n",
        "                wsum += w\n",
        "        out[col] = (acc/wsum) if wsum>0 else global_means[col]\n",
        "    return pd.Series(out)\n",
        "\n",
        "imputed_vals = df.apply(impute_row, axis=1)\n",
        "for col in num_cols:\n",
        "    df[col] = imputed_vals[col]\n",
        "\n",
        "df.to_csv(OUTDIR/\"_stage2_imputed.csv\", index=False)\n",
        "print(\"Imputation complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. Scaling and PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "imp = SimpleImputer(strategy=\"median\")\n",
        "X_imp = imp.fit_transform(df[num_cols])\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X_imp)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "exclude_for_dr = {'Cost_USD_per_kg', 'CO2_kg_per_kg', 'Cost_per_CO2', 'Eco_Index'}\n",
        "dr_cols = [c for c in num_cols if c not in exclude_for_dr]\n",
        "\n",
        "X_dr = pd.DataFrame(X_scaled, columns=num_cols)[dr_cols].values\n",
        "\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "pca_xy = pca.fit_transform(X_dr)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(df[\"PC1\"], df[\"PC2\"], s=8)\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(\"PCA (2D)\")\n",
        "plt.tight_layout(); plt.savefig(OUTDIR/\"pca_2d.png\", dpi=200); plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. KMeans (auto-k by silhouette)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best k: 3 silhouette: 0.9933995421162397\n"
          ]
        }
      ],
      "source": [
        "best_k, best_s = None, -1\n",
        "for k in range(2, 9):\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
        "    labels = km.fit_predict(X_scaled)\n",
        "    try:\n",
        "        score = silhouette_score(X_scaled, labels)\n",
        "    except Exception:\n",
        "        score = -1\n",
        "    if score > best_s:\n",
        "        best_s, best_k = score, k\n",
        "\n",
        "km = KMeans(n_clusters=best_k, random_state=42, n_init=\"auto\")\n",
        "df[\"Cluster\"] = km.fit_predict(X_scaled)\n",
        "plt.figure()\n",
        "plt.scatter(df[\"PC1\"], df[\"PC2\"], s=8, c=df[\"Cluster\"])\n",
        "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\"); plt.title(f\"PCA by KMeans (k={best_k})\")\n",
        "plt.tight_layout(); plt.savefig(OUTDIR/\"pca_kmeans.png\", dpi=200); plt.close()\n",
        "print(\"Best k:\", best_k, \"silhouette:\", best_s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8. Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr = pd.DataFrame(X_scaled, columns=num_cols).corr()\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.imshow(corr.values, aspect=\"auto\")\n",
        "plt.colorbar()\n",
        "plt.xticks(range(len(num_cols)), num_cols, rotation=90)\n",
        "plt.yticks(range(len(num_cols)), num_cols)\n",
        "plt.title(\"Correlation (scaled)\")\n",
        "plt.tight_layout(); plt.savefig(OUTDIR/\"correlation_matrix.png\", dpi=200); plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 9. Ashby Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing: Density UTS\n",
            "Missing: Density Elastic Modulus\n"
          ]
        }
      ],
      "source": [
        "def ashby(xcol, ycol, xlog=True, ylog=True, fname=\"ashby.png\", title=None):\n",
        "    if xcol not in df.columns or ycol not in df.columns: \n",
        "        print(\"Missing:\", xcol, ycol); return\n",
        "    x = pd.to_numeric(df[xcol], errors=\"coerce\")\n",
        "    y = pd.to_numeric(df[ycol], errors=\"coerce\")\n",
        "    m = ~x.isna() & ~y.isna()\n",
        "    if m.sum()==0: \n",
        "        print(\"No valid points for\", xcol, ycol); return\n",
        "    plt.figure()\n",
        "    plt.scatter(x[m], y[m], s=8)\n",
        "    if xlog: plt.xscale(\"log\")\n",
        "    if ylog: plt.yscale(\"log\")\n",
        "    plt.xlabel(xcol); plt.ylabel(ycol)\n",
        "    if title: plt.title(title)\n",
        "    plt.tight_layout(); plt.savefig(OUTDIR/fname, dpi=200); plt.close()\n",
        "\n",
        "ashby(\"Density\",\"UTS\", True, True, \"ashby_uts_density.png\", \"Ashby: UTS vs Density\")\n",
        "ashby(\"Density\",\"Elastic Modulus\", True, True, \"ashby_E_density.png\", \"Ashby: Elastic Modulus vs Density\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 10. TOPIS Ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TOPSIS features (present): ['Thermal Conductivity', 'Density', 'CO2_kg_per_kg']\n",
            "Saved: analysis_outputs\\materials_ranking_with_cost_env.csv\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "topsis_candidates = [\n",
        "    \"UTS\", \"Elastic Modulus\", \"Strength_to_Weight\", \"Specific_Stiffness\",\n",
        "    \"Thermal Conductivity\", \"Density\", \"Cost_USD_per_kg\", \"CO2_kg_per_kg\"\n",
        "]\n",
        "features = [c for c in topsis_candidates if c in df.columns]\n",
        "\n",
        "print(\"TOPSIS features (present):\", features)\n",
        "if features:\n",
        "    X = df[features].apply(pd.to_numeric, errors=\"coerce\").values\n",
        "\n",
        "    imp = SimpleImputer(strategy=\"median\")\n",
        "    X = imp.fit_transform(X)\n",
        "\n",
        "    col_norm = np.linalg.norm(X, axis=0)\n",
        "    col_norm[col_norm == 0] = 1.0\n",
        "    R = X / col_norm\n",
        "\n",
        "    dirs = np.array([ -1 if f in [\"Density\", \"Cost_USD_per_kg\", \"CO2_kg_per_kg\"] else 1\n",
        "                      for f in features ], dtype=float)\n",
        "\n",
        "    weights = []\n",
        "    for f in features:\n",
        "        if f in [\"UTS\", \"Elastic Modulus\", \"Strength_to_Weight\", \"Specific_Stiffness\"]:\n",
        "            weights.append(1.0)\n",
        "        elif f == \"Thermal Conductivity\":\n",
        "            weights.append(0.9)\n",
        "        elif f in [\"Cost_USD_per_kg\", \"CO2_kg_per_kg\"]:\n",
        "            weights.append(0.8)\n",
        "        else:\n",
        "            weights.append(0.6)\n",
        "    w = np.array(weights, dtype=float)\n",
        "    w = w / w.sum()\n",
        "\n",
        "    V = R * w\n",
        "\n",
        "    ideal_best  = np.where(dirs ==  1, V.max(axis=0), V.min(axis=0))\n",
        "    ideal_worst = np.where(dirs == -1, V.max(axis=0), V.min(axis=0))\n",
        "\n",
        "    d_pos = np.linalg.norm(V - ideal_best,  axis=1)\n",
        "    d_neg = np.linalg.norm(V - ideal_worst, axis=1)\n",
        "    score = d_neg / (d_pos + d_neg + 1e-12)\n",
        "\n",
        "    df_rank = pd.DataFrame({\"Material Name\": df.get(\"Material Name\", pd.Series(range(len(score))))})\n",
        "    for i, f in enumerate(features):\n",
        "        df_rank[f] = X[:, i]\n",
        "    df_rank[\"TOPSIS_score\"] = score\n",
        "    df_rank = df_rank.sort_values(\"TOPSIS_score\", ascending=False)\n",
        "\n",
        "    out_path = OUTDIR / \"materials_ranking_with_cost_env.csv\"\n",
        "    df_rank.to_csv(out_path, index=False)\n",
        "    print(\"Saved:\", out_path)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(score, bins=40)\n",
        "    plt.xlabel(\"TOPSIS score\"); plt.ylabel(\"Count\")\n",
        "    plt.title(\"TOPSIS score distribution (with Cost & CO2)\")\n",
        "    plt.tight_layout(); plt.savefig(OUTDIR/\"topsis_distribution_cost_env.png\", dpi=200); plt.close()\n",
        "else:\n",
        "    print(\"No valid TOPSIS features found; skipped.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11. Category-level summaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: analysis_outputs\\category_means.csv\n",
            "Saved: analysis_outputs\\_final_analysis_table.csv\n"
          ]
        }
      ],
      "source": [
        "def category_summary(df_in, cols):\n",
        "    rows = []\n",
        "    for _, r in df_in.iterrows():\n",
        "        cats = r[\"__categories_list\"] if isinstance(r[\"__categories_list\"], list) else []\n",
        "        for cat in cats:\n",
        "            e = {\"Category\": cat}\n",
        "            for c in cols: e[c] = r.get(c, np.nan)\n",
        "            rows.append(e)\n",
        "    if not rows: \n",
        "        return pd.DataFrame(columns=[\"Category\"]+cols)\n",
        "    temp = pd.DataFrame(rows)\n",
        "    return temp.groupby(\"Category\")[cols].mean().reset_index()\n",
        "\n",
        "summary_cols = [c for c in [\"UTS\",\"Elastic Modulus\",\"Density\",\"Thermal Conductivity\",\"Cost_USD_per_kg\",\"Eco_Index\"] if c in df.columns]\n",
        "cat_mean = category_summary(df, summary_cols)\n",
        "cat_mean.to_csv(OUTDIR/\"category_means.csv\", index=False)\n",
        "print(\"Saved:\", OUTDIR/\"category_means.csv\")\n",
        "\n",
        "df.to_csv(OUTDIR/\"_final_analysis_table.csv\", index=False)\n",
        "print(\"Saved:\", OUTDIR/\"_final_analysis_table.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11. Final Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: analysis_outputs\\_final_analysis_table.csv\n",
            "                                       Material Name    Density           PC1  \\\n",
            "0               Schott Glass 8347 Borosilicate Glass   2.230000  4.227790e-06   \n",
            "1  Morgan Advanced Ceramics Superwool® Plus Tank ...  52.564922  3.164500e-07   \n",
            "2                                            Hafnium  13.310000 -3.489278e-06   \n",
            "3  Chosun Refractories HSC-18RA Dense and High-St...  61.029983 -4.120852e-07   \n",
            "4                   MarkeTech CWO (Cadmium tungstate   7.900000  3.164752e-07   \n",
            "5                                    AISI 1137 Steel  25.912931 -1.453258e+03   \n",
            "6                                   AISI 4320H Steel  25.912931  1.546742e+03   \n",
            "7         Advanced Ceramics ACL 1091 (C-799) Alumina  61.029983 -4.120833e-07   \n",
            "8                     Mateck Gallium Arsenide (GaAs)   5.316000  1.163711e-07   \n",
            "9  Aremco Ceramabind™ 642-A High Temperature Inor...  44.694031  1.504707e-06   \n",
            "\n",
            "        PC2  Cluster  \n",
            "0 -1.718092        0  \n",
            "1  0.167245        0  \n",
            "2 -1.244857        0  \n",
            "3  0.501658        0  \n",
            "4 -1.581966        0  \n",
            "5 -0.737941        2  \n",
            "6 -0.737949        1  \n",
            "7  0.492579        0  \n",
            "8 -1.717646        0  \n",
            "9 -0.172390        0  \n"
          ]
        }
      ],
      "source": [
        "df.to_csv(OUTDIR/'_final_analysis_table.csv', index=False)\n",
        "print('Saved:', OUTDIR/'_final_analysis_table.csv')\n",
        "print(df[['Material Name'] + [c for c in ['UTS','Elastic Modulus','Density','Cost_USD_per_kg','Eco_Index','PC1','PC2','Cluster'] if c in df.columns]].head(10))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
